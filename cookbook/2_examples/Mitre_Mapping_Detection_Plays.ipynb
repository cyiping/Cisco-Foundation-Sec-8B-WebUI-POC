{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AI5ozM2h2Nva"
   },
   "source": [
    "# Use Case Description\n",
    "\n",
    "Security teams often write detection rules or response playbooks (e.g., for SIEMs, SOAR platforms, or XDRs) but struggle to systematically map them to the right MITRE ATT&CK techniques. This limits the organization’s visibility into detection coverage and hinders frameworks like D3FEND, ATT&CK Navigator, and threat-informed defense.\n",
    "\n",
    "The goal is to automatically analyze each detection play’s logic, objective, and context — and match it to the most relevant ATT&CK technique(s) with high confidence.\n",
    "\n",
    "## Model used for this use case\n",
    "Both Instruct Model and Reasoning Model can be used, but Instruct Model could work better as no complex reasoning is involved."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SetUp\n",
    "\n",
    "The setup scripts below are essentially the same as those in the [Quickstart (Instruct Model)](https://github.com/RobustIntelligence/foundation-ai-cookbook/blob/main/1_quickstarts/Preview_Quickstart_instruct_model.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "BPloud0h2LI9"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import transformers\n",
    "import torch\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "HF_TOKEN = os.getenv(\"HF_TOKEN\")\n",
    "\n",
    "def _get_device():\n",
    "    if torch.cuda.is_available():\n",
    "        return \"cuda\"\n",
    "    elif torch.backends.mps.is_available():\n",
    "        return \"mps\"\n",
    "    else:\n",
    "        return \"cpu\"\n",
    "\n",
    "DEVICE = _get_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "u5pjZGi32FsI"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a459ace1f6a54a9b9522fc67f0ada885",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "MODEL_ID = \"fdtn-ai/Foundation-Sec-8B-Instruct\"\n",
    "\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_ID, token=HF_TOKEN)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    pretrained_model_name_or_path=MODEL_ID,\n",
    "    device_map=\"auto\",\n",
    "    torch_dtype=torch.bfloat16, # this model's tensor_type is BF16\n",
    "    token=HF_TOKEN,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "v46D7fgiBNZF"
   },
   "outputs": [],
   "source": [
    "generation_args = {\n",
    "    \"max_new_tokens\": 512,\n",
    "    \"temperature\": None,\n",
    "    \"repetition_penalty\": 1.2,\n",
    "    \"do_sample\": False,\n",
    "    \"use_cache\": True,\n",
    "    \"eos_token_id\": tokenizer.eos_token_id,\n",
    "    \"pad_token_id\": tokenizer.pad_token_id,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def inference(prompt, system_prompt):\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": prompt},\n",
    "    ]\n",
    "    inputs = tokenizer.apply_chat_template(\n",
    "        messages, tokenize=False, add_generation_prompt=True\n",
    "    )\n",
    "    \n",
    "    inputs = tokenizer(inputs, return_tensors=\"pt\").to(DEVICE)\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            **inputs,\n",
    "            **generation_args,\n",
    "        )\n",
    "    response = tokenizer.decode(outputs[0], skip_special_tokens = False)\n",
    "    \n",
    "    # extract the assistant response part only\n",
    "    match = re.search(r\"<\\|assistant\\|>(.*?)<\\|end_of_text\\|>\", response, re.DOTALL)\n",
    "    \n",
    "    return match.group(1).strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yBOR3_hl8bIG"
   },
   "source": [
    "## MITRE Mapping Detection Plays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_PROMPT = \"You are a cybersecurity analyst provided with a series of threat detection plays. Each play includes its name and a short objective.\"\n",
    "\n",
    "def make_prompt(detection_plays):\n",
    "    return f'''Your task: For each detection play, map it to the most relevant MITRE ATT&CK technique. Include:\n",
    "    1. MITRE technique ID and name\n",
    "    2. Justification for the mapping\n",
    "    \n",
    "    ## DETECTION PLAYS\n",
    "    {detection_plays}\n",
    "    \n",
    "    Respond in a structured format:\n",
    "    - Play Name: <name>\n",
    "    - MITRE Technique: <TXXXX: Technique Name>\n",
    "    - Reason: <why it's a fit>'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "tP9VmFIK8r4_"
   },
   "outputs": [],
   "source": [
    "detection_plays = \"\"\"\n",
    "- Name: Monitor Multiple Failed Login Attempts\n",
    "  Objective: Detect brute-force attacks on user accounts by tracking repeated login failures.\n",
    "\n",
    "- Name: Alert on PowerShell Script Execution\n",
    "  Objective: Detect execution of potentially malicious PowerShell scripts by adversaries.\n",
    "\n",
    "- Name: Dumping LSASS credentials\n",
    "  Objective: Alert when attempts are made to dump credentials from LSASS process memory\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "OBsrE5qd9CFd"
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Here is how you can structure your response based on the given information:\n",
       "\n",
       "### Detection Plays Mapping\n",
       "\n",
       "#### 1. **Play Name:** Monitor Multiple Failed Login Attempts  \n",
       "   **MITRE Technique:** T1110.001: Password Guessing  \n",
       "   **Reason:** This technique involves an adversary attempting various combinations of account names and passwords to gain access to valid accounts. Monitoring multiple failed logon attempts helps identify such activities that could indicate a brute force attempt to gain unauthorized access.\n",
       "\n",
       "#### 2. **Play Name:** Alert on PowerShell Script Execution  \n",
       "   **MITRE Technique:** T1059.003: Command and Scripting Interpreter: Windows Command Shell (PowerShell)  \n",
       "   **Reason:** Adversaries use PowerShell as a command and scripting interpreter to execute commands, scripts, or loading modules. Alerts triggered upon script execution help detect this behavior which might be used for post-compromise behaviors like discovery, collection, or other techniques.\n",
       "\n",
       "#### 3. **Play Name:** Dumping LSASS credentials  \n",
       "   **MITRE Technique:** T1003.001: OS Credential Dumping: Security Account Manager  \n",
       "   **Reason:** The goal here is to alert on actions that may lead to credential dumping from lsass.exe, specifically targeting the Security Accounts Manager (SAM). This aligns with the MITRE ATT&CK technique T1003.001 because it describes methods attackers use to obtain sensitive credential material by accessing the SAM database within the Local Security Authority Subsystem Service (LSASS).\n",
       "\n",
       "Each entry maps a specific detection play to a corresponding MITRE ATT&CK technique, providing clarity on why these detections are effective against certain adversarial tactics, techniques, and procedures (TTPs)."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "response = inference(make_prompt(detection_plays), SYSTEM_PROMPT)\n",
    "display(Markdown(response))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
