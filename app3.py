import subprocess
import sys
import os

# ==========================================
# æ­¥é©Ÿ 0: è‡ªå‹•å®‰è£ç’°å¢ƒ
# ==========================================
def install_dependencies():
    print("æ­£åœ¨æª¢æŸ¥èˆ‡å®‰è£å¿…è¦å¥—ä»¶...")
    try:
        # åœ¨ Kaggle å®‰è£ bitsandbytes éœ€è¦ä¸€é»æ™‚é–“
        subprocess.check_call([
            sys.executable, "-m", "pip", "install", 
            "transformers", "accelerate", "bitsandbytes", "gradio", "huggingface_hub"
        ])
        print("ç’°å¢ƒå®‰è£å®Œæˆï¼")
    except Exception as e:
        print(f"å®‰è£éƒ¨åˆ†å¥—ä»¶å¤±æ•— (è‹¥æ˜¯ Kaggle é è£ç’°å¢ƒé€šå¸¸å¯å¿½ç•¥): {e}")

install_dependencies()

# ==========================================
# æ­¥é©Ÿ 1: è¼‰å…¥æ¨¡çµ„
# ==========================================
import time
import csv
import torch
import gradio as gr
from datetime import datetime
from transformers import (
    AutoModelForCausalLM, 
    AutoTokenizer, 
    pipeline, 
    BitsAndBytesConfig
)
from huggingface_hub import login

# ==========================================
# æ­¥é©Ÿ 2: æ¨¡å‹èˆ‡ç™»å…¥ (Kaggle Secrets æ”¯æ´)
# ==========================================
# å¦‚ä½•åœ¨ Kaggle è¨­å®š HF_TOKEN:
# 1. åœ¨ Kaggle Notebook é ‚éƒ¨é¸å–®é»æ“Š 'Add-ons' -> 'Secrets'ã€‚
# 2. é»æ“Š 'Add a new secret'ã€‚
# 3. Label è¼¸å…¥ 'HF_TOKEN'ï¼ŒValue è¼¸å…¥æ‚¨çš„ Hugging Face Access Tokenã€‚
# 4. å‹¾é¸è©² Secret æ—é‚Šçš„ 'Attached' è¤‡é¸æ¡†ä»¥å•Ÿç”¨å®ƒã€‚
# 5. ç¢ºä¿ Notebook å³å´é¢æ¿çš„ 'Internet' é¸é …å·²é–‹å•Ÿ (On)ã€‚
try:
    from kaggle_secrets import UserSecretsClient
    user_secrets = UserSecretsClient()
    hf_token = user_secrets.get_secret("HF_TOKEN")
    if hf_token:
        login(token=hf_token)
        print("âœ… Hugging Face ç™»å…¥æˆåŠŸ (via Secrets)")
except Exception:
    print("â„¹ï¸ æœªè¨­å®š Kaggle Secret 'HF_TOKEN'ï¼Œå°‡ä»¥åŒ¿åæ¨¡å¼ä¸‹è¼‰æ¨¡å‹ã€‚")

MODEL_ID = "fdtn-ai/Foundation-Sec-8B"
print(f"æ­£åœ¨è¼‰å…¥æ¨¡å‹: {MODEL_ID} (é€™åœ¨ Kaggle éœ€è¦å¹¾åˆ†é˜)...")

bnb_config = BitsAndBytesConfig(
    load_in_4bit=True,
    bnb_4bit_use_double_quant=True,
    bnb_4bit_quant_type="nf4",
    bnb_4bit_compute_dtype=torch.float16
)

try:
    tokenizer = AutoTokenizer.from_pretrained(MODEL_ID)
    if tokenizer.pad_token is None:
        tokenizer.pad_token = tokenizer.eos_token
    
    model = AutoModelForCausalLM.from_pretrained(
        MODEL_ID,
        quantization_config=bnb_config,
        device_map="auto",
        low_cpu_mem_usage=True
    )

    pipe = pipeline(
        "text-generation",
        model=model,
        tokenizer=tokenizer,
        return_full_text=False 
    )
    print("ğŸ‰ æ¨¡å‹è¼‰å…¥æˆåŠŸï¼")

except Exception as e:
    print(f"âŒ æ¨¡å‹è¼‰å…¥å¤±æ•—: {e}")
    print("è«‹ç¢ºèª: 1. å³å´ Internet æ˜¯å¦é–‹å•Ÿ?  2. æ˜¯å¦éœ€è¦ HF_TOKEN?")
    raise e

# Log è¨­å®š (Kaggle output path)
WORKING_DIR = "/kaggle/working" 
LOG_FILE = os.path.join(WORKING_DIR, "security_log.csv")

# ==========================================
# æ­¥é©Ÿ 3: ç”Ÿæˆé‚è¼¯ (Completion Prompt)
# ==========================================
def generate_security_analysis(prompt, max_tokens, temperature, top_p):
    start_time = time.time()
    try:
        full_prompt = f"""[Security Analysis Report]
Topic: {prompt}
Date: {datetime.now().strftime('%Y-%m-%d')}
Analyst: Automated Security System
Analysis Details:
"""
        output = pipe(
            full_prompt, 
            max_new_tokens=max_tokens, 
            do_sample=True, 
            temperature=temperature,
            top_p=top_p,
            pad_token_id=tokenizer.eos_token_id,
            repetition_penalty=1.2 
        )
        
        response = output[0]['generated_text'].strip()
        if not response: response = "(ç„¡å…§å®¹ç”Ÿæˆ)"

        # å¯«å…¥ Log
        duration = time.time() - start_time
        # ç¢ºä¿ç›®éŒ„å­˜åœ¨
        os.makedirs(WORKING_DIR, exist_ok=True)
        
        file_exists = os.path.isfile(LOG_FILE)
        with open(LOG_FILE, mode='a', newline='', encoding='utf-8-sig') as f:
            writer = csv.writer(f)
            if not file_exists:
                writer.writerow(["Timestamp", "Prompt", "Response", "Duration", "Params"])
            writer.writerow([
                datetime.now().strftime("%Y-%m-%d %H:%M:%S"), 
                prompt, 
                response, 
                f"{duration:.2f}",
                f"T={temperature}"
            ])
        return response

    except Exception as e:
        return f"Error: {str(e)}"

# ==========================================
# æ­¥é©Ÿ 4: Gradio ä»‹é¢
# ==========================================
custom_css = ".eta-stats { background: #f0f0f0 !important; }"

with gr.Blocks(title="Kaggle Security POC", theme=gr.themes.Soft(), css=custom_css) as demo:
    gr.Markdown("# ğŸ›¡ï¸ Kaggle Security Model POC (T4 Optimized)")
    
    with gr.Row():
        with gr.Column(scale=1):
            input_box = gr.Textbox(label="Input", placeholder="Enter CVE or Topic...", lines=5)
            with gr.Accordion("Parameters", open=False):
                max_tokens = gr.Slider(64, 2048, 512, step=64, label="Max Tokens")
                temp = gr.Slider(0.1, 1.0, 0.4, step=0.1, label="Temperature")
                top_p = gr.Slider(0.1, 1.0, 0.9, step=0.05, label="Top-p")
            submit = gr.Button("Generate", variant="primary")
            
        with gr.Column(scale=1):
            output = gr.Textbox(label="Output", lines=20, interactive=False, show_copy_button=True)

    submit.click(generate_security_analysis, [input_box, max_tokens, temp, top_p], output)

# Kaggle ä¸Šå¿…é ˆè¨­å®š share=True
demo.launch(share=True, debug=True)