# ==========================================
# æ­¥é©Ÿ 1: å®‰è£ç’°å¢ƒ (é‡å•Ÿ GPU å¾Œå¿…åš)
# ==========================================
import subprocess
import sys

def install_env():
    print("æ­£åœ¨æº–å‚™ç’°å¢ƒï¼Œè«‹ç¨å€™...")
    packages = ["sqlalchemy>=1.4", "transformers", "accelerate", "bitsandbytes", "gradio"]
    subprocess.check_call([sys.executable, "-m", "pip", "install", "-q"] + packages)
    print("ç’°å¢ƒå®‰è£å®Œæˆï¼")

install_env()

# ==========================================
# æ­¥é©Ÿ 2: è¼‰å…¥æ¨¡çµ„
# ==========================================
import os
import time
import csv
import torch
import gradio as gr
from datetime import datetime
from transformers import pipeline

# ==========================================
# æ­¥é©Ÿ 3: æ¨¡å‹åˆå§‹åŒ–
# ==========================================
print("æ­£åœ¨è¼‰å…¥ Foundation-Sec-8B æ¨¡å‹...")

pipe = pipeline(
    "text-generation", 
    model="fdtn-ai/Foundation-Sec-8B",
    model_kwargs={
        "torch_dtype": torch.float16,
        "load_in_4bit": True,      
        "device_map": "auto"       
    }
)

WORKING_DIR = "/kaggle/working"
LOG_FILE = os.path.join(WORKING_DIR, "security_log.csv")

# ==========================================
# æ­¥é©Ÿ 4: å®šç¾©ç”Ÿæˆé‚è¼¯
# ==========================================
def generate_security_analysis(prompt, max_tokens, temperature, top_p):
    start_time = time.time()
    try:
        output = pipe(
            prompt, 
            max_new_tokens=max_tokens, 
            do_sample=True, 
            temperature=temperature,
            top_p=top_p
        )
        full_text = output[0]['generated_text']
        response = full_text[len(prompt):].strip() if full_text.startswith(prompt) else full_text
        
        duration = time.time() - start_time
        file_exists = os.path.isfile(LOG_FILE)
        with open(LOG_FILE, mode='a', newline='', encoding='utf-8-sig') as f:
            writer = csv.writer(f)
            if not file_exists:
                writer.writerow(["Timestamp", "Prompt", "Response", "Duration"])
            writer.writerow([datetime.now(), prompt, response, f"{duration:.2f}"])
            
        return response
    except Exception as e:
        return f"ç™¼ç”ŸéŒ¯èª¤: {str(e)}"

# ==========================================
# æ­¥é©Ÿ 5: å»ºç«‹ä»‹é¢ (åƒæ•¸èˆ‡èªªæ˜ä¸€å°ä¸€çµ„åˆ)
# ==========================================

custom_css = """
.eta-stats {
    font-size: 30px !important;      
    line-height: 2.5 !important;    
    font-weight: bold !important;
    background: #FFF9C4 !important;  
    border: 4px solid #FBC02D !important;
    border-radius: 15px !important;
    padding: 10px 30px !important;
}
.generating {
    transform: scale(2.2) !important; 
    margin-right: 25px !important;
}
.title_center { text-align: center; }
/* è®“å»ºè­°å€¼çš„å­—é«”ç¨å¾®ç¸®å°ä¸¦å¸¶é»ç°ï¼Œæ›´åƒè¨»è§£ */
.hint-text { font-size: 0.85em; color: #555; margin-bottom: 2px; }
"""

with gr.Blocks(title="Cisco Security Model POC", theme=gr.themes.Default(), css=custom_css) as demo:
    gr.Markdown("# ğŸ›¡ï¸ Cisco Security Model POC", elem_classes="title_center")
    
    with gr.Row():
        # å·¦å´ï¼šè¼¸å…¥èˆ‡åƒæ•¸è¨­å®š
        with gr.Column(scale=1):
            input_box = gr.Textbox(
                label="Security Prompt (æå•)", 
                placeholder="ä¾‹å¦‚ï¼šè«‹åˆ†ææ­¤ CVE çš„è£œæ•‘å»ºè­°...",
                lines=8
            )
            
            # ä½¿ç”¨ Accordion ä¸¦åœ¨å…§éƒ¨å°‡èªªæ˜èˆ‡æ»‘æ¡¿ç¾¤çµ„
            with gr.Accordion("âš™ï¸ æ¨¡å‹åƒæ•¸è¨­å®š (å«å»ºè­°å€¼)", open=True):
                
                # Group 1: Max New Tokens
                gr.Markdown("**Max New Tokens: æ§åˆ¶å›è¦†é•·åº¦**", elem_classes="hint-text")
                gr.Markdown("*å»ºè­°ï¼šçŸ­åˆ†æè¨­ 512ï¼Œå®Œæ•´å ±å‘Šè¨­ 2048*", elem_classes="hint-text")
                max_tokens_slider = gr.Slider(minimum=128, maximum=4096, value=2048, step=128, label=None)
                
                gr.HTML("<hr style='margin: 10px 0;'>") # åˆ†éš”ç·š
                
                # Group 2: Temperature
                gr.Markdown("**Temperature: æ§åˆ¶éš¨æ©Ÿæ€§ (è¶Šä½è¶Šç²¾æº–)**", elem_classes="hint-text")
                gr.Markdown("*å»ºè­°ï¼šè³‡å®‰æŠ€è¡“åˆ†æè¨­ 0.1 - 0.4*", elem_classes="hint-text")
                temp_slider = gr.Slider(minimum=0.1, maximum=1.0, value=0.4, step=0.1, label=None)
                
                gr.HTML("<hr style='margin: 10px 0;'>") # åˆ†éš”ç·š
                
                # Group 3: Top-p
                gr.Markdown("**Top-p: æ§åˆ¶è©å½™é¸æ“‡ç¯„åœ**", elem_classes="hint-text")
                gr.Markdown("*å»ºè­°ï¼šä¿æŒåœ¨ 0.9*", elem_classes="hint-text")
                top_p_slider = gr.Slider(minimum=0.1, maximum=1.0, value=0.9, step=0.05, label=None)

            with gr.Row():
                clear_btn = gr.Button("Clear (æ¸…é™¤)")
                submit_btn = gr.Button("Submit (æäº¤åˆ†æ)", variant="primary")
            
        # å³å´ï¼šè¼¸å‡º
        with gr.Column(scale=1):
            output_display = gr.Textbox(
                label="Generation Result (åˆ†æçµæœ)", 
                placeholder="ç­‰å¾…æ¨¡å‹ç”Ÿæˆ...",
                lines=25,
                interactive=False,
                show_copy_button=True
            )
            flag_btn = gr.Button("Flag (ç´€éŒ„/æ¨™è¨˜å•é¡Œ)")

    # ç¶å®šåŠŸèƒ½
    submit_btn.click(
        fn=generate_security_analysis, 
        inputs=[input_box, max_tokens_slider, temp_slider, top_p_slider], 
        outputs=output_display
    )
    clear_btn.click(fn=lambda: ["", ""], outputs=[input_box, output_display])

# å•Ÿå‹•æœå‹™
demo.launch(share=True, debug=True)